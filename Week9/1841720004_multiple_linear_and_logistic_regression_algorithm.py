# -*- coding: utf-8 -*-
"""1841720004_Multiple_Linear_and_Logistic_Regression_Algorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YtSX_wtN1dxPZHaVam35cGCXD70lVMEi

# Building a predictive model using Multiple Linear Regression Algorithm
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams
rcParams['figure.figsize'] = (14,7)
rcParams['axes.spines.top'] = False
rcParams['axes.spines.right'] = False

class LinearRegression:
  '''
  A Class which implements linear regression model with gradient descent.
  '''

  def __init__(self, learning_rate=0.01, n_iterations=10000):
    self.learning_rate = learning_rate
    self.n_iterations = n_iterations
    self.weights, self.bias = None, None
    self.loss = []

  @staticmethod
  def _mean_squared_error(y, y_hat):
    '''
    Private method,used to evaluate loss at each iteratin.

    :param: y - array, true values
    :param: y_hat - array, predicted values
    :return: float
    '''

    error = 0
    for i in range(len(y)):
      error += (y[i] - y_hat[i]) ** 2
    return error / len(y)

  def fit(self, X, y):
    '''
    Used to calculate the coefficient of the linear regression model.

    :param X: array, features
    :param y: array, true values
    :return: None
    '''

    #1. Initialize weight and bias to zeros
    self.weights = np.zeros(X.shape[1])
    self.bias = 0

    #2 Perform gradient descent
    for i in range(self.n_iterations):
      #line equation
      y_hat = np.dot(X, self.weights) + self.bias
      loss = self._mean_squared_error(y, y_hat)
      self.loss.append(loss)

      #calculate derivatives
      partial_w = (1 / X.shape[0]) * (2 * np.dot(X.T, (y_hat - y)))
      partial_d = (1 / X.shape[0]) * (2 * np.sum(y_hat - y))

      # Update the coeffiecients
      self.weights -= self.learning_rate * partial_w
      self.bias -= self.learning_rate * partial_d

  
  def predict(self, X):
    ''' 
    Makes predictions using the line equation.

    :param X: array, features
    :return: array, predictions
    '''
    return np.dot(X, self.weights) + self.bias

# load dataset and splits into features and target arrays:
from sklearn.datasets import load_diabetes

data = load_diabetes()
X = data.data
y = data.target

# Split the dataset into training and testing subsets and to train the model.
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

model = LinearRegression()
model.fit(X_train, y_train)
preds = model.predict(X_test)
print(preds)
print(model._mean_squared_error(y_test, preds))

#the plotting of the loss
xs = np.arange(len(model.loss))
ys = model.loss

# Plotting of the loss
xs = np.arange(len(model.loss))
ys = model.loss

plt.plot(xs, ys, lw=3, c='#087E8B')
plt.title('Loss per iteration (MSE) ', size = 20)
plt.xlabel('Iteration ', size = 14)
plt.ylabel('Loss ', size = 14)
plt.show()

"""# Building a predictive model using Logistic Regression Algorith"""

from google.colab import files
import io
uploaded = files.upload()

# Logistic Regression on Diabetes Dataset
from random import seed
from random import randrange
from csv import reader
from math import exp
#load a CSV file
def load_csv(filename):
  dataset = list()
  with open(filename, 'r') as file:
    csv_reader = reader(file)
    for row in csv_reader:
      if not row:
        continue 
      dataset.append(row)
  return dataset

# Convert string column to float
def str_column_to_float(dataset, column):
  for row in dataset:
    row[column] = float(row[column].strip())

# FInd the min and max values for each column
def dataset_minmax(dataset):
  minmax = list()
  for i in range(len(dataset[0])):
    col_values = [row[i] for row in dataset]
    value_min = min(col_values)
    value_max = max(col_values)
    minmax.append([value_min, value_max])
  return minmax

# Rescale dataset columns to the range 0-1
def normalize_dataset(dataset, minmax):
  for row in dataset:
    for i in range(len(row)):
      row[i] = (row[i] - minmax[i][0] / minmax[i][1] - minmax[i][0])

# Split a dataset into k folds
def cross_validation_split(dataset, n_folds):
  dataset_split = list()
  dataset_copy = list(dataset)
  fold_size = int(len(dataset) / n_folds)
  for i in range(n_folds):
    fold = list()
    while len(fold) < fold_size:
      index = randrange(len(dataset_copy))
      fold.append(dataset_copy.pop(index))
    dataset_split.append(fold)
  return dataset_split

# Calculate accuracy percentage
def accuracy_metric(actual, predicted):
  correct = 0
  for i in range(len(actual)):
    if actual[i] == predicted[i]:
      correct += 1
  return correct / float(len(actual)) * 100.0

# Evaluate an alogorithm using a cross validation splits
def evaluate_algorithm(dataset, algorithm, n_folds, *args):
  folds = cross_validation_split(dataset, n_folds)
  scores = list()
  for fold in folds:
    train_set = list(folds)
    train_set.remove(fold)
    train_set = sum(train_set, [])
    test_set = list()
    for row in fold:
      row_copy = list(row)
      test_set.append(row_copy)
      row_copy[-1] = None
    predicted = algorithm(train_set, test_set, *args)
    actual = [row[-1] for row in fold]
    accuracy = accuracy_metric(actual, predicted)
    scores.append(accuracy)
  return scores

# Make a prediction with coefficients
def predict(row, coefficients):
  yhat = coefficients[0]
  for i in range(len(row)-1):
    yhat += coefficients[i + 1] * row[i]
    return 1.0 / (1.0 + exp(-yhat))

# Estimate logistic regression coefficients using stichastic gradient descent
def coefficients_sgd(train, l_rate, n_epoch):
  coef = [0.0 for i in range(len(train[0]))]
  for epoch in range(n_epoch):
    for row in train:
      yhat = predict(row, coef)
      error = row[-1] - yhat
      coef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)
      for i in range(len(row)-1):
        coef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]
  return coef

# Linear Regression Algorithm With Stochastic Gradient Descent
def logistic_regression(train, test, l_rate, n_epoch):
  predictions = list()
  coef = coefficients_sgd(train, l_rate, n_epoch)
  for row in test:
    yhat = predict(row, coef)
    yhat = round(yhat)
    predictions.append(yhat)
  return(predictions)

# Test the logistic regression algorrithm in the diabetes dataset
seed(1)
# load and prepare data
filename = 'pima-indians-diabetes.csv'
dataset = load_csv(filename)
for i in range(len(dataset[0])):
  str_column_to_float(dataset, i)

# Normalize
minmax = dataset_minmax(dataset)
normalize_dataset(dataset, minmax)

# Evalaute algorithm
n_folds = 5
l_rate = 0.1
n_epoch = 100
scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)
print('Scores: %s' %scores)
print('Mean Accuracy: %.3f%%' % (sum(scores) / float(len(scores))))